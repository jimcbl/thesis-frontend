(this["webpackJsonpmy-app"]=this["webpackJsonpmy-app"]||[]).push([[0],{46:function(e,t,a){e.exports=a(93)},51:function(e,t,a){},57:function(e,t,a){},93:function(e,t,a){"use strict";a.r(t);var n=a(0),r=a.n(n),l=a(18),i=a.n(l),s=(a(51),a(17)),o=a(20),c=function(){var e=Object(n.useState)(!1),t=Object(s.a)(e,2),a=t[0],l=t[1];return r.a.createElement("nav",{className:"navbar",role:"navigation","aria-label":"main navigation"},r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"navbar-brand"},r.a.createElement(o.b,{to:"/",id:"burgerMenu",className:"navbar-burger burger "+(a?"is-active":""),role:"button","aria-label":"menu","aria-expanded":"false","data-target":"menuContent",onClick:function(){return l(!a)}},r.a.createElement("span",{"aria-hidden":"true"}),r.a.createElement("span",{"aria-hidden":"true"}),r.a.createElement("span",{"aria-hidden":"true"}))),r.a.createElement("div",{id:"menuContent",className:"navbar-menu "+(a?"is-active":"")},r.a.createElement("div",{className:"navbar-start"},r.a.createElement(o.b,{to:"/",className:"navbar-item",onClick:function(){return l(!a)}},"Home"),r.a.createElement(o.b,{to:"/about-us",className:"navbar-item",onClick:function(){return l(!a)}},"About us")))))},m=(a(57),a(4)),u=(a(24),a(29),a(43),a(108),a(39),a(37),a(38),function(){return r.a.createElement("section",{className:"hero is-fullheight-with-navbar",id:"about-us"},r.a.createElement("div",{className:"hero-body"},r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"profiles"},r.a.createElement("div",{className:"profile"},r.a.createElement("div",{className:"avatar"},r.a.createElement("img",{className:"image",src:"https://storage.googleapis.com/dataset-nlp-dp2-1/static/ava_thu.jpg",alt:""})),r.a.createElement("p",{className:"name"},"Thu Tran"),r.a.createElement("p",{className:"content"},"My dream since childhood is to change the world. Now, as a wannabe adult, I'm trying to learn and improve myself as much as I can. Because baby steps count, right?")),r.a.createElement("div",{className:"profile"},r.a.createElement("div",{className:"avatar"},r.a.createElement("img",{className:"image",src:"https://storage.googleapis.com/dataset-nlp-dp2-1/static/ava_jim.jpg",alt:""})),r.a.createElement("p",{className:"name"},"Thinh Tran"),r.a.createElement("p",{className:"content"},"A fourth year student majoring in Computer Science. Logical but creative thinker. Possess adequate knowledge about media and technical related skills."))))))}),h=function(){return r.a.createElement("div",{className:"hero is-fullheight-with-navbar",id:"about-project"},r.a.createElement("div",{className:"container"},r.a.createElement("section",{className:"section"},r.a.createElement("header",null,r.a.createElement("h1",{className:"title is-1 has-text-weight-bold"},"Combination of voice recognition and language model for an end-to-end Vietnamese speech recognition"),r.a.createElement("p",{className:"subtitle meta"},"Students: Tran Ngoc Minh Thu - 1652599, Tran Duc Thinh - 1652578",r.a.createElement("br",null)," Instructors: Assoc. Prof. Quan Thanh Tho, Dr. Nguyen Duc Dung"))),r.a.createElement("section",{className:"section"},r.a.createElement("header",null,r.a.createElement("h3",{className:"title is-3"},"Acknowledgement")),r.a.createElement("p",{className:"content"},"We would love to show our deep and honest gratitude to Assoc. Prof. Qu\u1ea3n Th\xe0nh Th\u01a1 and Dr. Nguy\u1ec5n \u0110\u1ee9c D\u0169ng. We are eternally grateful and indebted to your guidance, advice, enthusiasm and encouragement in helping us researching and implementing this project."),r.a.createElement("p",{className:"content"},"We wish to express our appreciation to all of our faculty lecturers, without whom we would not have the necessary knowledge to finish our project. Later, when equipped with precious expertise from this university, we will be confidently heading into our future and be phenomenal."),r.a.createElement("p",{className:"content"},"We also wish to acknowledge the support from our family and friends (D\u0169ng, To\xe0n, Nh\u01b0, Duy, ...), for they always stand by us"),r.a.createElement("p",{className:"content"},"Despite our commitment, we are aware that this project is still inadequate and contains inevitable errors. We would love to receive feedback from lecturers in order to improve furthermore."),r.a.createElement("p",{className:"content"},"Finally, we wish you health, prosperity, and success in your chosen paths")),r.a.createElement("section",{className:"section"},r.a.createElement("h3",{className:"title is-3"},"Abstract"),r.a.createElement("p",{className:"content"},"The speech to text problem is not uncommon, since automatic speech recognition is an important feature in the modern world. There are some existing models regarding this particular problem. However, there are few, if not rare, existing models for languages other than English. This is because of the differences in the characteristics of each language, so the implementation of speech to text systems varies remarkably for each country. Our graduation project is to build a Vietnamese end-to-end automatic speech recognition for extracurricular activities, using voice recognition and language model, based on the Deep Speech 2 model.")),r.a.createElement("section",{className:"section"},r.a.createElement("h3",{className:"title is-3"},"Introduction"),r.a.createElement("p",{className:"content"},"Our university has very active and energetic extracurricular activities. The activities are usually organized by a group of students. They handle, inform and announce information through a Facebook fan page. So when big events are approaching, such as Mua He Xanh, Xuan Tinh Nguyen,\u2026 the fan page that organizes those activities are usually bombarded with a lot of questions from students. But the number of admins is not enough to handle all of those, so the process is quite slow and frustrating. Students have to wait for a while before they can get their answers."),r.a.createElement("p",{className:"content"},"Our thesis is a part of a bigger application, which can enhance and improve the user experience when using chat applications to ask for services about extracurricular activities. This application includes 2 parts: an ASR system for transferring speech to text so that students don\u2019t have to type since speaking is much faster, and an Intelligent Chatbot so that students can get the information they need automatically, without depending on manual interactions. Our thesis focuses on the ASR system, which is built under the influence of the renowned Deep Speech 2.")),r.a.createElement("section",{className:"section"},r.a.createElement("h3",{className:"title is-3"},"Voice recognizer"),r.a.createElement("p",{className:"content"},"Based on Deep Speech 2, our Voice Recognizer has the following architecture: 2 layers of CNN, 2 layers of bidirectional RNN with LSTM and hidden layer size of 600, 1 fully connected layer. The input is an audio file, represented as a Spectrogram. After having this spectrogram go through the neural network, the text will go through CTC (Connectionist Temporal Classification). Then we will have a raw text from the audio. This raw text will be the input for further correction from our Language Model.")),r.a.createElement("section",{className:"section"},r.a.createElement("h3",{className:"title is-3"},"Language model"),r.a.createElement("p",{className:"content"},"In order to produce the most correct transcript out of the user\u2019s audio input, we use Language Model. A statistical language model is a probability distribution over sequences of words. The general problem statement for the language model is to correct Vietnamese sentences with wrong spelling. In this thesis, it means that the language model will correct the sentence generated from the Voice Recognizer Our language model is the Left2Right and Right2Left model.")),r.a.createElement("section",{className:"section"},r.a.createElement("h3",{className:"title is-3"},"Our data"),r.a.createElement("p",{className:"content"},"We recorded about 1500 audio files based on scripts of students asking for information about extracurricular activities. In total, it is approximately 2 hours. After the augmentation, including adding noise, changing speed, adding padding, we have around 10 hours in total.")),r.a.createElement("section",{className:"section"},r.a.createElement("h3",{className:"title is-3"},"Result"),r.a.createElement("p",{className:"content"},"Result for testing untrained audio files that were recorded in a complete different environment and going through the Language Model"),r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"content"},"Example result:",r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement("b",null,"Ground truth:")," CHO M\xccNH H\u1eceI CH\xdaT V\u1ec0 TI\u1ebeP S\u1ee8C M\xd9A THI V\u1eda"),r.a.createElement("li",null,r.a.createElement("b",null,"From Voice recognition system:")," CHO M\xccNH H\u1eceI CH\xdaT V\u1ec0 T\u1ebeP S\u1ee8C T\xd9A THIN V\u1edaI"),r.a.createElement("li",null,r.a.createElement("b",null,"After Language model:")," CHO M\xccNH H\u1eceI CH\xdaT V\u1ec0 TI\u1ebeP S\u1ee8C M\xd9A THI V\u1edaI"))),r.a.createElement("table",{className:"table is-bordered  is-narrow"},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null),r.a.createElement("th",null,"Without LM"),r.a.createElement("th",null,"Apply LM"))),r.a.createElement("tbody",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Word Error Rate"),r.a.createElement("td",null,"0.33207"),r.a.createElement("td",null,"0.17601")),r.a.createElement("tr",null,r.a.createElement("th",null,"Character Error Rate"),r.a.createElement("td",null,"0.13199"),r.a.createElement("td",null,"0.11574"))))),r.a.createElement("p",{className:"content"},"We also have a workable ASR system that can be used to ask for university extracurricular activities.")),r.a.createElement("div",{className:"flex-wrapper"},r.a.createElement("section",{className:"section section--evaluation"},r.a.createElement("h3",{className:"title is-3"},"Evaluation"),r.a.createElement("div",{className:"content"},r.a.createElement("ul",null,r.a.createElement("li",{className:"mt-1"},r.a.createElement("p",null,r.a.createElement("b",null,"Achievements:")," We have learned many new things and gained a lot of experience while doing this thesis"),r.a.createElement("ul",null,r.a.createElement("li",null,"The ability to collect and self-generate data"),r.a.createElement("li",null,"The implementation of Deep Speech 2 model for Vietnamese transcription"),r.a.createElement("li",null,"Achievements in experiences, knowledge, and soft skill"))),r.a.createElement("li",{className:"mt-1"},r.a.createElement("p",null,r.a.createElement("b",null,"Drawbacks:")," We are aware that this project still contains inevitable errors. We would love to receive feedback in order to improve furthermore"),r.a.createElement("ul",null,r.a.createElement("li",null," Data limitation"),r.a.createElement("li",null,"Lack of computing capability"),r.a.createElement("li",null," Time constraint"))),r.a.createElement("li",{className:"mt-1 is-width-81"},r.a.createElement("p",null,r.a.createElement("b",null,"Future improvements:")," With just a small amount of self generating data, the model showed promising results within our scope. So the Vietnamese ASR can certainly be improved in the future"),r.a.createElement("ul",null,r.a.createElement("li",null,"Collect and generate more data"),r.a.createElement("li",null,"Tuning the model with different configurations for observation, hence being able to pick the most efficient model"))))))),r.a.createElement("div",{className:"figure-wrapper"})))},d=function(){return r.a.createElement("div",{className:"main-thesis"},r.a.createElement(o.a,{basename:"/thesis-frontend"},r.a.createElement(c,null),r.a.createElement(m.c,null,r.a.createElement(m.a,{exact:!0,path:"/",component:h}),r.a.createElement(m.a,{path:"/about-us",component:u}),r.a.createElement(m.a,{component:function(){return r.a.createElement("div",null,"404 Not found ")}}))))};Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));i.a.render(r.a.createElement(r.a.StrictMode,null,r.a.createElement(d,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}},[[46,1,2]]]);
//# sourceMappingURL=main.9450c3e1.chunk.js.map